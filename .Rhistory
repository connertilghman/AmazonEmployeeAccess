mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train) |>
update_role(MGR_ID, new_role="id") |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
step_other(all_nominal_predictors(), threshold = 0.001) |>
step_dummy(all_nominal_predictors()) |>
step_range(all_numeric_predictors(), min=0, max=1)
nn_model <- mlp(hidden_units = tune(),
epochs = 50 )|>
set_engine("keras") |>
set_mode("classification")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(nn_model)
tuning_grid <- grid_regular(hidden_units(range=c(1, 20)),
levels = 5)
folds <- vfold_cv(train, v = 5, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
keras::install_keras()
install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
reticulate::install_python()
keras::install_keras()
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
reticulate::install_python()
install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
reticulate::install_python()
keras::install_keras()
install.packages("remotes")
remotes::install_github("rstudio/tensorflow")
py_config()
install_tensorflow()
reticulate::install_python()
py_config()
install_tensorflow()
keras::install_keras()
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
sample <- vroom("sampleSubmission.csv")
test <- vroom("test.csv")
train <- vroom("train.csv")
train <- train |>
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train) |>
update_role(MGR_ID, new_role="id") |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
step_other(all_nominal_predictors(), threshold = 0.001) |>
step_dummy(all_nominal_predictors()) |>
step_range(all_numeric_predictors(), min=0, max=1)
nn_model <- mlp(hidden_units = tune(),
epochs = 50 )|>
set_engine("keras") |>
set_mode("classification")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(nn_model)
tuning_grid <- grid_regular(hidden_units(range=c(1, 20)),
levels = 5)
folds <- vfold_cv(train, v = 5, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
tensorflow::install_tensorflow()
install.packages("tensorflow")
remotes::install_github("rstudio/tensorflow")
reticulate::install_python()
keras::install_keras()
tensorflow::install_tensorflow()
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
library(keras)
library(tensorflow)
library(reticulate)
venv_path <- file.path(virtualenv_root(), "r-tensorflow")
if (dir.exists(venv_path)) {
message("Removing broken r-tensorflow environment...")
unlink(venv_path, recursive = TRUE)
}
if (!tensorflow::tf_available()) {
message("Installing Miniconda and TensorFlow...")
install_miniconda()
install_tensorflow(envname = "r-tensorflow")
}
use_virtualenv("r-tensorflow", required = TRUE)
conda_list()
install_miniconda()
use_virtualenv("r-tensorflow", required = TRUE)
tf$constant("âœ… TensorFlow is ready!")
install.packages("remotes")
reticulate::install_python()
keras::install_keras()
tensorflow::install_tensorflow()
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
library(keras)
library(tensorflow)
library(reticulate)
train <- train |>
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train) |>
update_role(MGR_ID, new_role="id") |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
step_other(all_nominal_predictors(), threshold = 0.001) |>
step_dummy(all_nominal_predictors()) |>
step_range(all_numeric_predictors(), min=0, max=1)
prep_rec <- prep(my_recipe)
baked_data <- bake(prep_rec, new_data = train)
nn_model <- mlp(hidden_units = tune(),
epochs = 50 )|>
set_engine("keras") |>
set_mode("classification")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(nn_model)
tuning_grid <- grid_regular(hidden_units(range=c(1, 20)),
levels = 5)
folds <- vfold_cv(train, v = 5, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
library(keras)
sample <- vroom("sampleSubmission.csv")
test <- vroom("test.csv")
train <- vroom("train.csv")
train <- train |>
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train) |>
update_role(MGR_ID, new_role="id") |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
step_other(all_nominal_predictors(), threshold = 0.001) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_predictors()) |>
step_pca(all_predictors(), threshold= .5) |>
step_range(all_numeric_predictors(), min=0, max=1)
forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) |>
set_engine("ranger") |>
set_mode("classification")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(forest_mod)
tuning_grid <- grid_regular(mtry(range = c(1)),
min_n(range = c(2)),
levels = 5)
forest_mod <- rand_forest(mtry = 1,
min_n=5,
trees=500) |>
set_engine("ranger") |>
set_mode("classification")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(forest_mod)
tuning_grid <- grid_regular(levels = 3)
forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) |>
set_engine("ranger") |>
set_mode("classification")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(forest_mod)
tuning_grid <- grid_regular(mtry(range = c(2,4)),
min_n(range = c(2, 4)),
levels = 3)
folds <- vfold_cv(train, v = 2, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
View(CV_results)
remove.packages(c("tensorflow", "keras", "reticulate"))
reticulate::virtualenv_remove("r-reticulate")
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
sample <- vroom("sampleSubmission.csv")
test <- vroom("test.csv")
train <- vroom("train.csv")
summary(train)
train <- train |>
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train) |>
update_role(MGR_ID, new_role="id") |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
step_other(all_nominal_predictors(), threshold = 0.001) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_predictors()) |>
step_pca(all_predictors(), threshold= .2) |>
step_range(all_numeric_predictors(), min=0, max=1)
svmRadial <- svm_rbf(rbf_sigma=tune(), cost=tune()) |>
set_mode("classification") |>
set_engine("kernlab")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(svmRadial)
tuning_grid <- grid_regular(rbf_sigma(),
cost(),
levels = 3)
folds <- vfold_cv(train, v = 2, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
View(CV_results)
bestTune <- CV_results |>
select_best(metric = "roc_auc")
bestTune <- CV_results |>
select_best(metric = "roc_auc")
final_wf <- amazon_workflow |>
finalize_workflow(bestTune) |>
fit(data=train)
svm_preds <- predict(final_wf, new_data = test, type="prob")
View(sample)
View(svm_preds)
kaggle_submission <- test|>
bind_cols(svm_preds)|>
select(id, .pred_1) |>
rename(Action=.pred_1) |>
rename(Id=id)
vroom_write(x=kaggle_submission, file="./SVMPreds.csv", delim=",")
forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) |>
set_engine("ranger") |>
set_mode("classification")
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(forest_mod)
tuning_grid <- grid_regular(rbf_sigma(),
cost(),
levels = 3)
folds <- vfold_cv(train, v = 2, repeats=1)
tuning_grid <- grid_regular(mtry(range = c(1, 20)),
min_n(range = c(2, 10)),
levels = 3)
folds <- vfold_cv(train, v = 2, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
n_cores <- parallel::detectCores() - 1
cl <- makeCluster(n_cores)
registerDoParallel(cl)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
View(CV_results)
bestTune <- CV_results |>
select_best(metric = "roc_auc")
final_wf <- amazon_workflow |>
finalize_workflow(bestTune) |>
fit(data=train)
forest_preds <- predict(final_wf, new_data = test, type="prob")
kaggle_submission <- test|>
bind_cols(forest_preds)|>
select(id, .pred_1) |>
rename(Action=.pred_1) |>
rename(Id=id)
vroom_write(x=kaggle_submission, file="./ForestPreds.csv", delim=",")
View(forest_preds)
vroom_write(x=kaggle_submission, file="./ForestPreds.csv", delim=",")
kaggle_submission <- test|>
bind_cols(forest_preds)|>
select(id, .pred_1) |>
rename(Action=.pred_1) |>
rename(Id=id)
vroom_write(x=kaggle_submission, file="./ForestPreds.csv", delim=",")
my_recipe <- recipe(ACTION ~ ., data = train) |>
update_role(MGR_ID, new_role="id") |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
step_other(all_nominal_predictors(), threshold = 0.001) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_predictors()) |>
step_pca(all_predictors(), threshold= .5) |>
step_range(all_numeric_predictors(), min=0, max=1)
forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) |>
set_engine("ranger") |>
set_mode("classification")
n_cores <- parallel::detectCores() - 1
cl <- makeCluster(n_cores)
registerDoParallel(cl)
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(forest_mod)
tuning_grid <- grid_regular(mtry(range = c(1, 20)),
min_n(range = c(2, 10)),
levels = 3)
folds <- vfold_cv(train, v = 2, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
View(CV_results)
bestTune <- CV_results |>
select_best(metric = "roc_auc")
final_wf <- amazon_workflow |>
finalize_workflow(bestTune) |>
fit(data=train)
forest_preds <- predict(final_wf, new_data = test, type="prob")
kaggle_submission <- test|>
bind_cols(forest_preds)|>
select(id, .pred_1) |>
rename(Action=.pred_1) |>
rename(Id=id)
vroom_write(x=kaggle_submission, file="./ForestPreds.csv", delim=",")
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
library(themis)
install.packages("themis")
library(themis)
sample <- vroom("sampleSubmission.csv")
test <- vroom("test.csv")
train <- vroom("train.csv")
train <- train |>
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train) |>
update_role(MGR_ID, new_role="id") |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
step_other(all_nominal_predictors(), threshold = 0.001) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_predictors()) |>
step_pca(all_predictors(), threshold= .5) |>
step_range(all_numeric_predictors(), min=0, max=1) |>
step_smote(all_outcomes(), neighbors=10)
forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) |>
set_engine("ranger") |>
set_mode("classification")
n_cores <- parallel::detectCores() - 1
cl <- makeCluster(n_cores)
registerDoParallel(cl)
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(forest_mod)
tuning_grid <- grid_regular(mtry(range = c(1, 20)),
min_n(range = c(2, 10)),
levels = 3)
folds <- vfold_cv(train, v = 2, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
View(CV_results)
bestTune <- CV_results |>
select_best(metric = "roc_auc")
final_wf <- amazon_workflow |>
finalize_workflow(bestTune) |>
fit(data=train)
forest_preds <- predict(final_wf, new_data = test, type="prob")
kaggle_submission <- test|>
bind_cols(forest_preds)|>
select(id, .pred_1) |>
rename(Action=.pred_1) |>
rename(Id=id)
vroom_write(x=kaggle_submission, file="./SmotePreds.csv", delim=",")
stopCluster(cl)
registerDoSEQ()
library(discrim)
library(tidymodels)
library(vroom)
library(patchwork)
library(doParallel)
library(dplyr)
library(glmnet)
library(themis)
sample <- vroom("sampleSubmission.csv")
test <- vroom("test.csv")
train <- vroom("train.csv")
train <- train |>
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data = train) |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
#step_other(all_nominal_predictors(), threshold = .001) %>%
# combines categorical values that occur
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) |>
step_normalize(all_predictors()) #target encoding
library(tidyverse)
library(patchwork)
library(tidymodels)
library(embed)
install.packages("embed")
library(tidyverse)
library(patchwork)
library(tidymodels)
library(embed)
library(vroom)
library(discrim)
library(kernlab)
library(themis)
prep_rec <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data = train) |>
step_mutate_at(all_numeric_predictors(), fn = factor) |>
#step_other(all_nominal_predictors(), threshold = .001) %>%
# combines categorical values that occur
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) |>
step_normalize(all_predictors()) #target encoding
forest_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=1000) |>
set_engine("ranger") |>
set_mode("classification")
n_cores <- parallel::detectCores() - 1
cl <- makeCluster(n_cores)
registerDoParallel(cl)
amazon_workflow <- workflow() |>
add_recipe(my_recipe) |>
add_model(forest_mod)
tuning_grid <- grid_regular(mtry(range = c(1,9)),
min_n(),
levels=5)
folds <- vfold_cv(train, v=10, repeats=1)
control <- control_grid(save_pred = FALSE, save_workflow = FALSE, verbose = FALSE)
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
install.packages("lme4")
CV_results <- amazon_workflow |>
tune_grid(
resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc),
control = control)
View(CV_results)
bestTune <- CV_results |>
select_best(metric = "roc_auc")
final_wf <- amazon_workflow |>
finalize_workflow(bestTune) |>
fit(data=train)
forest_preds <- predict(final_wf, new_data = test, type="prob")
kaggle_submission <- test|>
bind_cols(forest_preds)|>
select(id, .pred_1) |>
rename(Action=.pred_1) |>
rename(Id=id)
vroom_write(x=kaggle_submission, file="./NewForestPreds.csv", delim=",")
stopCluster(cl)
registerDoSEQ()
